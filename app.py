import streamlit as st
import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import time
import os
import gdown 

# Cáº¤U HÃŒNH DATA VÃ€ MODEL (ID GOOGLE DRIVE Cá»¦A Báº N ÄÃƒ ÄÆ¯á»¢C DÃN VÃ€O ÄÃ‚Y)
DATA_FILE = 'anime_dataset_small_nomic.parquet'
DATA_FILE_ID = '16bdNhA2DCgRevE3ZtaQIIym_lSRYVqQO' 
MODEL_NAME = 'nomic-ai/nomic-embed-text-v1.5'

# --- 1. Táº£i Dá»¯ liá»‡u, Táº¡o Index vÃ  Model (Chá»‰ cháº¡y 1 láº§n) ---
@st.cache_resource
def load_data_and_initialize_rag():
    # 1. Táº¢I FILE Dá»® LIá»†U Tá»ª GOOGLE DRIVE Náº¾U CHÆ¯A Tá»’N Táº I
    if not os.path.exists(DATA_FILE):
        try:
            # Gdown sáº½ táº£i file vÃ  lÆ°u vá»›i tÃªn DATA_FILE
            gdown.download(id=DATA_FILE_ID, output=DATA_FILE, quiet=True, fuzzy=True)
        except Exception as e:
            st.error(f"Lá»–I Táº¢I DATA: KhÃ´ng thá»ƒ táº£i file tá»« Google Drive. Vui lÃ²ng kiá»ƒm tra ID vÃ  quyá»n chia sáº». Lá»—i: {e}")
            return None, None, None
    
    # 2. Äá»ŒC Dá»® LIá»†U
    try:
        df = pd.read_parquet(DATA_FILE)
    except Exception as e:
        st.error(f"Lá»–I Äá»ŒC FILE: KhÃ´ng thá»ƒ Ä‘á»c file Parquet. Lá»—i: {e}")
        return None, None, None

    # 3. Táº O TRÆ¯á»œNG CONTEXT RAG
    try:
        df['rag_context'] = (
            "Title: " + df['Main Title'].fillna('Unknown Title') + " | " +
            "Studio: " + df['Animation Work'].fillna('Unknown Studio') + " | " +
            "Tags: " + df['Tags'].fillna('No tags') + " | " + 
            "Synopsis: " + df['Synopsis'].fillna('No synopsis provided')
        )
    except KeyError as e:
        st.error(f"Lá»–I KEY: Cá»™t {e} khÃ´ng tá»“n táº¡i. Vui lÃ²ng kiá»ƒm tra láº¡i chÃ­nh táº£ tÃªn cá»™t.")
        return None, None, None

    # 4. Táº£i MÃ´ hÃ¬nh Embedding 
    try:
        model = SentenceTransformer(MODEL_NAME, trust_remote_code=True)
    except Exception as e:
        st.error(f"Lá»–I: KhÃ´ng thá»ƒ táº£i mÃ´ hÃ¬nh embedding. Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i internet. Lá»—i chi tiáº¿t: {e}")
        return None, None, None
    
    # 5. Táº¡o Embeddings vÃ  Index FAISS
    embedding_texts = df['rag_context'].tolist()
    embeddings = model.encode(embedding_texts, show_progress_bar=False)
    
    # Táº¡o Index FAISS
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings).astype('float32'))
    
    return df, model, index

# --- 2. HÃ m TÃ¬m kiáº¿m Ngá»¯ nghÄ©a ---
def semantic_search(query: str, df: pd.DataFrame, model: SentenceTransformer, index: faiss.Index, k: int = 5):
    """Thá»±c hiá»‡n tÃ¬m kiáº¿m vector vÃ  tráº£ vá» cÃ¡c anime phÃ¹ há»£p nháº¥t."""
    
    query_embedding = model.encode([query]) 
    distances, indices = index.search(np.array(query_embedding).astype('float32'), k)
    
    results = df.iloc[indices[0]].copy()
    results['Distance'] = distances[0]
    
    return results.sort_values(by='Distance', ascending=True)

# --- 3. Giao diá»‡n Streamlit ---

# Cáº¥u hÃ¬nh trang (cháº¿ Ä‘á»™ Wide)
st.set_page_config(
    page_title="AiMi Anime Recommender",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# TiÃªu Ä‘á» chÃ­nh
st.markdown("<h1 style='text-align: center; color: #FF69B4;'>ğŸ’– AiMi Anime Recommender ğŸ¤–</h1>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align: center; color: #808080;'>TÃ¬m kiáº¿m Anime báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn sá»­ dá»¥ng Vector AI</h4>", unsafe_allow_html=True)


# Sá»­ dá»¥ng st.spinner Ä‘á»ƒ áº©n cÃ¡c bÆ°á»›c ká»¹ thuáº­t
with st.spinner("ğŸš€ Äang khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng Äá» xuáº¥t AI... (Láº§n Ä‘áº§u sáº½ máº¥t vÃ i phÃºt)"):
    df, model, index = load_data_and_initialize_rag()

if df is not None:
    st.success("âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng! ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i tháº¿ giá»›i Anime.")
    st.markdown("---")
    
    # CONTAINER CHO THANH TÃŒM KIáº¾M VÃ€ SLIDER
    search_container = st.container()
    with search_container:
        col1, col2 = st.columns([4, 1])
        
        with col1:
            user_query = st.text_input(
                "ğŸ’¬ Nháº­p mÃ´ táº£ Anime báº¡n muá»‘n tÃ¬m:",
                "Dark fantasy anime with tragic character arcs and moral ambiguity",
                placeholder="VÃ­ dá»¥: Slice of life comedy set in high school with healing atmosphere"
            )
        
        with col2:
            k_recommendations = st.slider("Sá»‘ lÆ°á»£ng:", 1, 10, 5, help="Chá»n sá»‘ lÆ°á»£ng anime báº¡n muá»‘n Ä‘Æ°á»£c Ä‘á» xuáº¥t.")

    # KHá»I CHáº Y TÃŒM KIáº¾M
    if user_query:
        start_time = time.time()
        
        # Thá»±c hiá»‡n tÃ¬m kiáº¿m
        with st.spinner(f"ğŸ” Äang tÃ¬m kiáº¿m ngá»¯ nghÄ©a cho '{user_query}'..."):
            recommendations = semantic_search(user_query, df, model, index, k_recommendations)
        
        end_time = time.time()
        
        st.markdown(f"## Top {k_recommendations} Äá» xuáº¥t PhÃ¹ há»£p:")
        st.caption(f"ğŸ” TÃ¬m kiáº¿m hoÃ n táº¥t trong {end_time - start_time:.4f} giÃ¢y.")
        
        # HIá»‚N THá»Š Káº¾T QUáº¢ DÆ¯á»šI Dáº NG CARD
        for i, row in recommendations.iterrows():
            # Sá»­ dá»¥ng st.container Ä‘á»ƒ táº¡o má»™t "card" cÃ³ ná»n vÃ  Ä‘á»™ ná»•i báº­t nháº¹
            with st.container(border=True):
                main_title = row.get('Main Title', 'N/A')
                official_en = row.get('Official Title (en)', 'N/A')
                max_rating = row.get('Max Rating', 0.0)
                filter_year = int(row.get('filter_year', 0))
                animation_work = row.get('Animation Work', 'N/A')
                synopsis = row.get('Synopsis', 'KhÃ´ng cÃ³ tÃ³m táº¯t')
                tags_content = row.get('Tags', 'KhÃ´ng cÃ³ tháº»')
                similarity = 1 - row['Distance']

                col_info, col_rating = st.columns([3, 1])
                
                with col_info:
                    st.markdown(f"### âœ¨ {main_title} *({official_en})*")
                    st.markdown(f"**ğŸ¬ Studio:** {animation_work} | **ğŸ“… NÄƒm:** {filter_year}")
                    st.markdown(f"**ğŸ·ï¸ Thá»ƒ loáº¡i:** *{tags_content}*")
                    st.markdown(f"**ğŸ“– TÃ³m táº¯t:** {synopsis}")
                
                with col_rating:
                    # Hiá»ƒn thá»‹ Rating vÃ  Äá»™ TÆ°Æ¡ng Ä‘á»“ng báº±ng st.metric
                    st.metric(label="â­ ÄÃ¡nh giÃ¡ (10)", value=f"{max_rating:.2f}")
                    st.metric(label="ğŸ¯ Äá»™ tÆ°Æ¡ng Ä‘á»“ng", value=f"{similarity:.4f}")
